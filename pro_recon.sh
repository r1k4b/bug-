#!/usr/bin/env bash
# pro_recon.sh тАФ Adaptive, session-aware recon (Bangla prompts) v1.1
# Author: Generated by an AI assistant at your request
#
# рж▓ржХрзНрж╖рзНржп: ржЕржирзБржорзЛржжрж┐ржд рж╕рзНржХрзЛржкрзЗ ржирж┐рж░рж╛ржкржж ржУ рж╕ржорзНржорж╛ржиржЬржиржХ рж░рж┐ржХржи (pro recon) ржЪрж╛рж▓рж╛ржирзЛ,
# antiтАСbot/тАЬhumanтАЭ ржЪрзНржпрж╛рж▓рзЗржЮрзНржЬ ржзрж░рж╛ ржкржбрж╝рж▓рзЗ рж╕рзНржмржпрж╝ржВржХрзНрж░рж┐ржпрж╝ржнрж╛ржмрзЗ passiveтАСfirst ржорзЛржбрзЗ рж╕рзНржпрзБржЗржЪ ржХрж░рж╛,
# ржПржмржВ ржкрзНрж░ржпрж╝рзЛржЬржирзЗ session-aware (headers/cookies) ржХрзНрж░рж▓ ржЪрж╛рж▓рж╛ржирзЛред
#
# тЪая╕П рж╕рждрж░рзНржХрждрж╛
# - рж╢рзБржзрзБржорж╛рждрзНрж░ ржЕржирзБржорзЛржжрж┐ржд ржЯрж╛рж░рзНржЧрзЗржЯрзЗ ржЪрж╛рж▓рж╛ржи (BBP/VDP/рж▓рж┐ржЦрж┐ржд ржкрж╛рж░ржорж┐рж╢ржирж╕рж╣)уАВ
# - CAPTCHA/WAF ржмрж╛ржЗржкрж╛рж╕ ржХрж░рж╛рж░ ржХрзМрж╢рж▓ ржмрзНржпржмрж╣рж╛рж░рзЗрж░ ржЙржжрзНржжрзЗрж╢рзНржпрзЗ ржиржпрж╝ред
# - рж░рзЗржЯтАСрж▓рж┐ржорж┐ржЯ ржмржЬрж╛ржпрж╝ рж░рж╛ржЦрзБржи; рж╕рж╛рж░рзНржнрж╛рж░ржХрзЗ ржУржнрж╛рж░рж▓рзЛржб ржХрж░ржмрзЗржи ржирж╛ред
#
# ржирж┐рж░рзНржнрж░рж╢рзАрж▓ ржЯрзБрж▓рж╕ (auto-detected; ржирж╛ ржерж╛ржХрж▓рзЗ ржзрж╛ржкрзЗ ржзрж╛ржкрзЗ ржХржо ржлрж┐ржЪрж╛рж░ ржмрзНржпржмрж╣рж╛рж░ рж╣ржмрзЗ):
# subfinder, dnsx, httpx, gau, waybackurls, katana, nuclei, gf, anew, uro, zip
# ржРржЪрзНржЫрж┐ржХ: naabu, subzy, jq (storageState.json ржкрж╛рж░рзНрж╕ ржХрж░рждрзЗ)
#
# ржмрзНржпржмрж╣рж╛рж░:
#   ./pro_recon.sh [options] <domain>
# ржЕржкрж╢ржи:
#   -p, --profile <passive|safe|full>   рж╕рзНржХрзНржпрж╛ржи ржкрзНрж░рзЛржлрж╛ржЗрж▓ (ржбрж┐ржлрж▓рзНржЯ: safe)
#   -H, --headers-file <file>           ржХрж╛рж╕рзНржЯржо HTTP headers (Cookie рж╕рж╣) ржлрж╛ржЗрж▓ (header: value рж▓рж╛ржЗржирзЗ)
#   -C, --cookies <netscape_cookies>    Netscape cookies.txt ржжрж┐рж▓рзЗ Cookie рж╣рзЗржбрж╛рж░ ржмрж╛ржирж┐ржпрж╝рзЗ -H ржП ржпрзЛржЧ ржХрж░рж╛ рж╣ржмрзЗ
#       --storage-state <file>          Playwright storageState.json (jq рж▓рж╛ржЧржмрзЗ) тЖТ Cookie рж╣рзЗржбрж╛рж░ рж╕рзЗржЯ
#   -S, --scope-file <file>             ржЗржи-рж╕рзНржХрзЛржк regex/prefix рждрж╛рж▓рж┐ржХрж╛ (ржкрзНрж░рждрж┐ рж▓рж╛ржЗржирзЗ ржПржХржЯрж┐)
#   -o, --outdir <dir>                  ржЖржЙржЯржкрзБржЯ ржлрзЛрж▓рзНржбрж╛рж░ (ржбрж┐ржлрж▓рзНржЯ: ржЬрж┐ржЬрзНржЮрзЗрж╕ ржХрж░ржмрзЗ)
#       --no-active                     ржПржХрзЗржмрж╛рж░рзЗ passive-only (HTTP fetch/nuclei/katana ржмржирзНржз)
#       --force-active                  anti-bot ржзрж░рж╛ ржкржбрж╝рж▓рзЗржУ active ржЪрж╛рж▓рж╛ржмрзЗ
#       --hl                            katana headless рж╕ржХрзНрж╖ржо ржХрж░рзБржи (ржпржжрж┐ ржЗржирж╕рзНржЯрж▓ ржерж╛ржХрзЗ)
#       --wait-for-cookies <path>       anti-bot/403 ржзрж░рж╛ ржкржбрж╝рж▓рзЗ ржПржЦрж╛ржирзЗ cookies.txt ржЖрж╕рж╛ ржкрж░рзНржпржирзНржд pauseтЖТresume
#       --on-403 <pause|passive|retry>  403/429/anti-bржЯ рж╣рж▓рзЗ ржЖржЪрж░ржг (ржбрж┐ржлрж▓рзНржЯ: passive)
#   -h, --help                          рж╕рж╛рж╣рж╛ржпрзНржп
#
# ржЙржжрж╛рж╣рж░ржг:
#   ./pro_recon.sh -p safe -H headers.txt --hl example.com
#   ./pro_recon.sh -p full -C cookies.txt -S scope.txt example.com
#   ./pro_recon.sh -p safe --wait-for-cookies cookies.txt --on-403 pause example.com
#
set -Eeuo pipefail
shopt -s inherit_errexit

# ---------- helpers ----------
RED=$'\e[31m'; GRN=$'\e[32m'; YLW=$'\e[33m'; BLU=$'\e[34m'; DIM=$'\e[2m'; RST=$'\e[0m'
ts() { date '+%Y-%m-%d %H:%M:%S'; }
ok()  { echo -e "${GRN}[$(ts)]$RST $*"; }
warn(){ echo -e "${YLW}[$(ts)]$RST $*"; }
err() { echo -e "${RED}[$(ts)] ERROR:$RST $*" >&2; }

need_cmd() { command -v "$1" >/dev/null 2>&1; }

usage() { sed -n '1,120p' "$0" | sed -n 's/^# //p' | sed -n '1,110p'; exit 1; }

# ---------- parse args ----------
PROFILE="safe"
HEADERS_FILE=""
COOKIES_FILE=""
STORAGE_STATE_FILE=""
SCOPE_FILE=""
OUT_DIR=""
NO_ACTIVE=false
FORCE_ACTIVE=false
KATANA_HEADLESS=false
WAIT_COOKIES_PATH=""
ON_403="passive"

domain=""

while [[ $# -gt 0 ]]; do
  case "$1" in
    -p|--profile) PROFILE="${2:-}"; shift 2;;
    -H|--headers-file) HEADERS_FILE="${2:-}"; shift 2;;
    -C|--cookies) COOKIES_FILE="${2:-}"; shift 2;;
    --storage-state) STORAGE_STATE_FILE="${2:-}"; shift 2;;
    -S|--scope-file) SCOPE_FILE="${2:-}"; shift 2;;
    -o|--outdir) OUT_DIR="${2:-}"; shift 2;;
    --no-active) NO_ACTIVE=true; shift;;
    --force-active) FORCE_ACTIVE=true; shift;;
    --hl) KATANA_HEADLESS=true; shift;;
    --wait-for-cookies) WAIT_COOKIES_PATH="${2:-}"; shift 2;;
    --on-403) ON_403="${2:-}"; shift 2;;
    -h|--help) usage;;
    -*)
      err "Unknown option: $1"; usage;;
    *)
      if [[ -z "$domain" ]]; then domain="$1"; else err "Extra arg: $1"; usage; fi
      shift;;
  esac
done

[[ -z "${domain:-}" ]] && usage

# Ask output dir if not passed
if [[ -z "${OUT_DIR:-}" ]]; then
  read -rp "ЁЯФ╕ ржкрзЗржиржбрзНрж░рж╛ржЗржн/ржЖржЙржЯржкрзБржЯ ржлрзЛрж▓рзНржбрж╛рж░рзЗрж░ ржкрже ржжрж┐ржи (ржпрзЗржоржи: /mnt/e/bughunt): " OUT_DIR
  [[ -z "$OUT_DIR" ]] && { err "ржкрж╛рже ржЦрж╛рж▓рж┐ рж░рж╛ржЦрж╛ ржпрж╛ржмрзЗ ржирж╛"; exit 1; }
fi

SCAN_DIR="${OUT_DIR}/${domain}_scan_$(date +%Y%m%d_%H%M%S)"
mkdir -p "$SCAN_DIR"
LIVE_LOG="$SCAN_DIR/live_results.txt"; : >"$LIVE_LOG"

UA="pro-recon/2025 (+authorized testing)"
export KATANA_CONFIG=""

# ---------- headers utils ----------
MERGED_HEADERS="$SCAN_DIR/headers.merged.txt"
: > "$MERGED_HEADERS"

set_cookie_header() {
  local cookie_str="$1"
  [[ -z "$cookie_str" ]] && return 0
  awk 'BEGIN{IGNORECASE=1} !/^Cookie:[[:space:]]/ {print}' "$MERGED_HEADERS" > "$MERGED_HEADERS.tmp" || true
  mv "$MERGED_HEADERS.tmp" "$MERGED_HEADERS"
  echo "Cookie: $cookie_str" >> "$MERGED_HEADERS"
  ok "Cookie рж╣рзЗржбрж╛рж░ рж╕рзЗржЯ рж╣ржпрж╝рзЗржЫрзЗред"
}

merge_user_headers() {
  if [[ -n "${HEADERS_FILE:-}" && -s "${HEADERS_FILE:-}" ]]; then
    awk 'NF && $0 !~ /^#/ {print}' "$HEADERS_FILE" >> "$MERGED_HEADERS"
  fi
}

merge_cookies_netscape() {
  if [[ -n "${COOKIES_FILE:-}" && -s "${COOKIES_FILE:-}" ]]; then
    local cookie_str
    cookie_str=$(awk 'NF && $0 !~ /^#/ {printf "%s=%s; ", $6, $7} END{print ""}' "$COOKIES_FILE" | sed 's/; $//')
    [[ -n "$cookie_str" ]] && set_cookie_header "$cookie_str"
    ok "Netscape cookies.txt ржерзЗржХрзЗ Cookies ржпрзБржХрзНржд рж╣ржпрж╝рзЗржЫрзЗред"
  fi
}

merge_storage_state() {
  if [[ -n "${STORAGE_STATE_FILE:-}" && -s "${STORAGE_STATE_FILE:-}" ]]; then
    if need_cmd jq; then
      local cookie_str
      cookie_str=$(jq -r '[.cookies[] | "\(.name)=\(.value)"] | join("; ")' "$STORAGE_STATE_FILE" 2>/dev/null || true)
      [[ -n "$cookie_str" && "$cookie_str" != "null" ]] && set_cookie_header "$cookie_str" && ok "storageState.json ржерзЗржХрзЗ Cookies ржпрзБржХрзНржд рж╣ржпрж╝рзЗржЫрзЗред" || warn "storageState.json ржерзЗржХрзЗ ржХрзБржХрж┐ ржкржбрж╝рж╛ ржЧрзЗрж▓ ржирж╛ред"
    else
      warn "jq ржирзЗржЗ; --storage-state ржХрж╛ржЬ ржХрж░ржмрзЗ ржирж╛ред jq ржЗржирзНрж╕ржЯрж▓ ржХрж░рзЗ ржЖржмрж╛рж░ ржЪрзЗрж╖рзНржЯрж╛ ржХрж░рзБржиред"
    fi
  fi
}

merge_user_headers
merge_cookies_netscape
merge_storage_state

[[ -s "$MERGED_HEADERS" ]] || true

# ---------- tool detection ----------
req_tools=(subfinder dnsx httpx gau waybackurls nuclei)
opt_tools=(katana gf anew uro zip naabu subzy jq)

missing=()
for t in "${req_tools[@]}"; do need_cmd "$t" || missing+=("$t"); done

if ((${#missing[@]})); then
  warn "ржХрж┐ржЫрзБ ржкрзНрж░ржпрж╝рзЛржЬржирзАржпрж╝ ржЯрзБрж▓ ржирзЗржЗ: ${missing[*]}"
  warn "ржПрж╕ржм ржирж╛ ржерж╛ржХрж▓рзЗ ржлрж┐ржЪрж╛рж░ ржХржорзЗ ржпрзЗрждрзЗ ржкрж╛рж░рзЗ; рж╕рзНржХрзНрж░рж┐ржкрзНржЯ ржпрждржЯрж╛ рж╕ржорзНржнржм fallback ржирзЗржмрзЗред"
fi

# ---------- profile -> throttle ----------
case "$PROFILE" in
  passive)
    ACTIVE_ALLOWED=false; HTTPX_THREADS=10; NUCLEI_RATE=10; NUCLEI_BULK=10; KATANA_RL=25; KATANA_CONC=5;;
  safe|SAFE)
    ACTIVE_ALLOWED=true;  HTTPX_THREADS=25; NUCLEI_RATE=25; NUCLEI_BULK=15; KATANA_RL=50; KATANA_CONC=10;;
  full|FULL)
    ACTIVE_ALLOWED=true;  HTTPX_THREADS=50; NUCLEI_RATE=75; NUCLEI_BULK=25; KATANA_RL=100; KATANA_CONC=20;;
  *)
    warn "ржЕржЬрж╛ржирж╛ ржкрзНрж░рзЛржлрж╛ржЗрж▓ '$PROFILE' тЖТ safe ржзрж░рж╛ рж╣рж▓рзЛ"; 
    ACTIVE_ALLOWED=true;  HTTPX_THREADS=25; NUCLEI_RATE=25; NUCLEI_BULK=15; KATANA_RL=50; KATANA_CONC=10;;
esac

$NO_ACTIVE && ACTIVE_ALLOWED=false
$FORCE_ACTIVE && ACTIVE_ALLOWED=true

# ---------- anti-bot detection ----------
detect_antibot() {
  local url="https://${domain}/"
  local cmd=(curl -m 15 -sSL -A "$UA" -D -)
  if [[ -s "$MERGED_HEADERS" ]]; then
    while IFS= read -r line; do
      [[ -z "$line" || "$line" =~ ^# ]] && continue
      cmd+=(-H "$line")
    done < "$MERGED_HEADERS"
  fi
  local resp
  resp="$("${cmd[@]}" "$url" 2>/dev/null | tr -d '\r')"
  if grep -qiE 'cf-ray|cloudflare|captcha|hcaptcha|recaptcha|Access Denied|verify you are human|Just a moment' <<<"$resp"; then
    return 0
  else
    return 1
  fi
}

wait_for_cookies() {
  local path="$1"
  [[ -z "$path" ]] && return 0
  warn "anti-bot/403 ржзрж░рж╛ ржкржбрж╝рзЗржЫрзЗ тАФ cookies ржлрж╛ржЗрж▓рзЗрж░ ржЬржирзНржп ржЕржкрзЗржХрзНрж╖рж╛ ржХрж░рж╛ рж╣ржЪрзНржЫрзЗ: $path"
  warn "ржмрзНрж░рж╛ржЙржЬрж╛рж░рзЗ human+login рж╢рзЗрж╖ ржХрж░рзЗ cookies Netscape ржлрж░ржорзНржпрж╛ржЯрзЗ рж╕рзЗржн ржХрж░рзБржи; Ctrl+C ржжрж┐рж▓рзЗ ржмрж╛рждрж┐рж▓ред"
  while true; do
    if [[ -s "$path" ]]; then
      warn "cookies ржлрж╛ржЗрж▓ ржкрж╛ржУржпрж╝рж╛ ржЧрзЗржЫрзЗ тАФ ржорж╛рж░рзНржЬ ржХрж░рж╛ рж╣ржЪрзНржЫрзЗ..."
      COOKIES_FILE="$path"
      merge_cookies_netscape
      ok "cookies ржорж╛рж░рзНржЬ рж╕ржорзНржкржирзНржиред"
      return 0
    fi
    sleep 3
    echo -n "."
  done
}

AUTOMODE_NOTE=""
if ! $FORCE_ACTIVE && detect_antibot; then
  warn "anti-bot/\"human\" ржЪрзНржпрж╛рж▓рзЗржЮрзНржЬ рж╢ржирж╛ржХрзНржд рж╣ржпрж╝рзЗржЫрзЗред"
  case "$ON_403" in
    pause)
      if [[ -n "$WAIT_COOKIES_PATH" ]]; then
        wait_for_cookies "$WAIT_COOKIES_PATH"
        ACTIVE_ALLOWED=true
        AUTOMODE_NOTE="(resumed with cookies after anti-bot)"
      else
        warn "--on-403=pause ржжрзЗржпрж╝рж╛ рж╣ржпрж╝рзЗржЫрзЗ ржХрж┐ржирзНрждрзБ --wait-for-cookies ржирзЗржЗ; passive-first рж╣ржмрзЗред"
        ACTIVE_ALLOWED=false
        AUTOMODE_NOTE="(auto passive-first due to anti-bot)"
      fi
      ;;
    retry)
      warn "--on-403=retry: active рж░рж╛ржЦрж╛рж░ ржЪрзЗрж╖рзНржЯрж╛ ржХрж░рж╛ рж╣ржмрзЗ (рж╕рзЗржл ржерзНрж░ржЯрж▓ рж╕рж╣)ред"
      ACTIVE_ALLOWED=true
      AUTOMODE_NOTE="(retry mode under anti-bot)"
      ;;
    passive|*)
      warn "--on-403=passive: active ржзрж╛ржкржЧрзБрж▓рзЛ рж╕рзАржорж┐ржд ржХрж░рж╛ рж╣ржмрзЗ (passive-first)ред"
      ACTIVE_ALLOWED=false
      AUTOMODE_NOTE="(auto passive-first due to anti-bot)"
      ;;
  esac
fi

# ---------- scope helpers ----------
in_scope_filter() {
  if [[ -n "${SCOPE_FILE:-}" && -s "$SCOPE_FILE" ]]; then
    awk -v RS='\n' 'FNR==NR {a[$0]; next} { for (k in a) { if (k!="" && $0 ~ k) { print; break } } }' "$SCOPE_FILE" -
  else
    cat
  fi
}

dedupe() {
  if need_cmd anew; then anew
  else awk '!seen[$0]++'
  fi
}

normalize_urls() {
  if need_cmd uro; then uro
  else cat
  fi
}

ok "ржЯрж╛рж░рзНржЧрзЗржЯ: ${domain}  ржкрзНрж░рзЛржлрж╛ржЗрж▓: ${PROFILE} ${AUTOMODE_NOTE}"
[[ -s "$MERGED_HEADERS" ]] && ok "Headers in use: $MERGED_HEADERS"
[[ -n "${SCOPE_FILE:-}" ]] && ok "Scope file: $SCOPE_FILE"
ok "ржЖржЙржЯржкрзБржЯ: $SCAN_DIR"
echo ""

# ========== [1] Subdomain enum ==========
ok "[1/8] Subdomain enum (subfinder тЖТ dnsx)..."
: > "$SCAN_DIR/subdomains.raw.txt"
: > "$SCAN_DIR/subdomains.txt"

if need_cmd subfinder; then
  subfinder -silent -d "$domain" | in_scope_filter | dedupe > "$SCAN_DIR/subdomains.raw.txt" || true
else
  warn "subfinder ржирзЗржЗ; subdomain ржзрж╛ржк рж╕рзНржХрж┐ржкред"
fi

if need_cmd dnsx; then
  if [[ -s "$SCAN_DIR/subdomains.raw.txt" ]]; then
    dnsx -silent -a -resp -l "$SCAN_DIR/subdomains.raw.txt" \
      | tee "$SCAN_DIR/dnsx_resolved.txt" >/dev/null
    awk '{print $1}' "$SCAN_DIR/dnsx_resolved.txt" | dedupe > "$SCAN_DIR/subdomains.txt" || true
  fi
else
  warn "dnsx ржирзЗржЗ; raw subdomains рж░рж╛ржЦрж▓рж╛ржоред"
  cp "$SCAN_DIR/subdomains.raw.txt" "$SCAN_DIR/subdomains.txt" || true
fi

# ========== [2] HTTP probe (httpx) ==========
: > "$SCAN_DIR/origins.txt"
if need_cmd httpx && [[ -s "$SCAN_DIR/subdomains.txt" ]]; then
  ok "[2/8] HTTP probe (httpx) тАФ ржХржо-ржкрзНрж░рждрж┐-рж╕рзЗржХрзЗржирзНржб ржерзНрж░рзЗржб ржжрж┐ржпрж╝рзЗ..."
  httpx -l "$SCAN_DIR/subdomains.txt" -silent -title -status-code -follow-redirects \
        -threads "$HTTPX_THREADS" -timeout 10 \
        | tee -a "$LIVE_LOG" >/dev/null

  if grep -E '\s(403|429)\s' "$LIVE_LOG" >/dev/null 2>&1; then
    warn "HTTP probe-ржП 403/429 ржжрзЗржЦрж╛ ржЧрзЗржЫрзЗред"
    case "$ON_403" in
      pause)
        if [[ -n "$WAIT_COOKIES_PATH" ]]; then
          wait_for_cookies "$WAIT_COOKIES_PATH"
          ok "cookies ржкрж╛ржУржпрж╝рж╛рж░ ржкрж░ httpx ржкрзБржирж░рж╛ржпрж╝ ржЪрж╛рж▓рж╛ржирзЛ рж╣ржЪрзНржЫрзЗ..."
          httpx -l "$SCAN_DIR/subdomains.txt" -silent -title -status-code -follow-redirects \
                -threads "$HTTPX_THREADS" -timeout 10 \
                | tee -a "$LIVE_LOG" >/dev/null || true
          ACTIVE_ALLOWED=true
        else
          warn "--on-403=pause ржХрж┐ржирзНрждрзБ --wait-for-cookies ржирзЗржЗ; passive-first ржП ржирж╛ржорж╛ рж╣ржЪрзНржЫрзЗред"
          ACTIVE_ALLOWED=false
        fi
        ;;
      retry)
        warn "retry ржорзЛржбрзЗ active ржЪрж╛рж▓рзБ ржерж╛ржХржмрзЗ; рж░рзЗржЯ-рж▓рж┐ржорж┐ржЯрзЗрж░ ржХрж╛рж░ржгрзЗ ржХрж┐ржЫрзБ ржмрзНрж▓ржХ ржерж╛ржХрждрзЗ ржкрж╛рж░рзЗред"
        ACTIVE_ALLOWED=true
        ;;
      passive|*)
        warn "passive ржорзЛржбрзЗ ржирж╛ржорж╛ рж╣ржЪрзНржЫрзЗред"
        ACTIVE_ALLOWED=false
        ;;
    esac
  fi

  httpx -l "$SCAN_DIR/subdomains.txt" -silent -ports 80,443 -threads "$HTTPX_THREADS" \
        -no-color | sed 's/\x1b\[[0-9;]*m//g' | dedupe > "$SCAN_DIR/origins.txt" || true
else
  warn "httpx ржирзЗржЗ ржмрж╛ subdomains ржЦрж╛рж▓рж┐; origins рж╕рзНржХрж┐ржкред"
fi

# ========== [3] Passive URLs (waybackurls+gau) ==========
ok "[3/8] Passive URLs (waybackurls + gau)..."
: > "$SCAN_DIR/passive_urls.txt"
( (need_cmd waybackurls && echo "$domain" | waybackurls || true) ; \
  (need_cmd gau && gau --subs "$domain" || true) ) \
  | in_scope_filter | normalize_urls | dedupe > "$SCAN_DIR/passive_urls.txt"

# ========== [4] Auth/session-aware crawl (katana) ==========
: > "$SCAN_DIR/katana_urls.txt"
if $ACTIVE_ALLOWED && need_cmd katana; then
  ok "[4/8] Katana crawl (session-aware, JS-aware)..."
  KATANA_FLAGS=(-silent -jc -d 3 -rl "$KATANA_RL" -c "$KATANA_CONC")
  $KATANA_HEADLESS && KATANA_FLAGS+=(-hl)
  [[ -s "$MERGED_HEADERS" ]] && KATANA_FLAGS+=(-H "$MERGED_HEADERS")
  if [[ -s "$SCAN_DIR/origins.txt" ]]; then
    katana -list "$SCAN_DIR/origins.txt" "${KATANA_FLAGS[@]}" -o "$SCAN_DIR/katana_urls.txt" || true
  else
    katana -u "https://${domain}" "${KATANA_FLAGS[@]}" -o "$SCAN_DIR/katana_urls.txt" || true
  fi
else
  warn "katana рж╕рзНржХрж┐ржк (ACTIVE_ALLOWED=${ACTIVE_ALLOWED}, tool=$(need_cmd katana && echo ok || echo missing))."
fi

# ========== [5] URL merge & filtering ==========
ok "[5/8] URL merge & filtering..."
cat "$SCAN_DIR/passive_urls.txt" "$SCAN_DIR/katana_urls.txt" 2>/dev/null \
  | in_scope_filter | normalize_urls | dedupe > "$SCAN_DIR/all_urls.txt"
ok "ржорзЛржЯ URL: $(wc -рж▓ <"$SCAN_DIR/all_urls.txt" 2>/dev/null || echo 0)"

# GF patterns (optional)
if need_cmd gf && [[ -s "$SCAN_DIR/all_urls.txt" ]]; then
  ok "GF ржкрзНржпрж╛ржЯрж╛рж░рзНржирж╕..."
  mkdir -p "$SCAN_DIR/gf"
  for p in xss sqli lfi rce redirect idor ssrf interestingparams; do
    grep -Ei '.' "$SCAN_DIR/all_urls.txt" | gf "$p" | dedupe > "$SCAN_DIR/gf/${p}.txt" || true
  done
fi

# ========== [6] Nuclei (rate-limited) ==========
if $ACTIVE_ALLOWED && need_cmd nuclei && [[ -s "$SCAN_DIR/all_urls.txt" ]]; then
  ok "[6/8] nuclei (infoтЖТcritical, rate=${NUCLEI_RATE}/s, bulk=${NUCLEI_BULK})..."
  NUCLEI_FLAGS=(-severity info,low,medium,high,critical -bulk-size "$NUCLEI_BULK" -rate-limit "$NUCLEI_RATE" -retries 1 -timeout 10 -silent)
  [[ -s "$MERGED_HEADERS" ]] && NUCLEI_FLAGS+=( -H "$MERGED_HEADERS" )
  nuclei -l "$SCAN_DIR/all_urls.txt" "${NUCLEI_FLAGS[@]}" \
    | stdbuf -oL sed 's/^/[nuclei] /' | tee -a "$LIVE_LOG"
else
  warn "nuclei рж╕рзНржХрж┐ржк (ACTIVE_ALLOWED=${ACTIVE_ALLOWED} ржмрж╛ URLs ржирзЗржЗ ржмрж╛ tool ржирзЗржЗ)ред"
fi

# ========== [7] (Optional) Subdomain takeover & ports ==========
if need_cmd subzy && [[ -s "$SCAN_DIR/subdomains.txt" ]]; then
  ok "[7/8] Subdomain takeover (subzy)..."
  subzy run --targets "$SCAN_DIR/subdomains.txt" --output "$SCAN_DIR/subzy_takeover.txt" || true
fi
if need_cmd naabu && [[ -s "$SCAN_DIR/subdomains.txt" ]]; then
  ok "ржкрзЛрж░рзНржЯ рж╕рзНржХрзНржпрж╛ржи (naabu тАФ рж▓рж╛ржЗржЯ ржорзЛржб)..."
  naabu -l "$SCAN_DIR/subdomains.txt" -top-ports 100 -silent -o "$SCAN_DIR/naabu_top100.txt" || true
fi

# ========== [8] Zip & summary ==========
ok "[8/8] рж░рж┐ржкрзЛрж░рзНржЯ ржЬрж┐ржк ржХрж░рж╛ рж╣ржЪрзНржЫрзЗ..."
if need_cmd zip; then
  (cd "$SCAN_DIR/.." && zip -qr "$(basename "$SCAN_DIR").zip" "$(basename "$SCAN_DIR")") || true
else
  warn "zip ржЯрзБрж▓ ржирзЗржЗ; ржЬрж┐ржк рж╕рзНржХрж┐ржкред"
fi

ok "тЬЕ рж╕ржм ржХрж╛ржЬ рж╢рзЗрж╖!"
ok "ЁЯУБ ржлрзЛрж▓рзНржбрж╛рж░: $SCAN_DIR"
[[ -f "$SCAN_DIR.zip" ]] && ok "ЁЯУж ржЬрж┐ржк: $SCAN_DIR.zip"
ok "ЁЯУД рж▓рж╛ржЗржн рж▓ржЧ ржжрзЗржЦрждрзЗ: tail -f \"$LIVE_LOG\""

# End.
